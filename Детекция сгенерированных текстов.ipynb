{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":98885,"databundleVersionId":11800270,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Название проекта**  \n\nДетекция сгенерированных текстов    \n(https://www.kaggle.com/competitions/you-are-bot)\n_____\n\n**Цель исследования**  \n\nРазработать модель, которая по тексту диалога с наибольшей точностью будет определять, является ли участник диалога ботом или нет\n_______\n**Задачи исследования**\n\n- Загрузка и анализ данных о диалогах.\n- Формирование класса и соответствующий набор функций для извлечения текстовых и поведенческих признаков\n- Извлечение эмбеддингов с использованием трансформеров\n- Создание и обучение ансамбля моделей для классификации текстов\n- Произведение оценки качества классификации на основе метрики LogLoss\n- Выполнить предсказания на тесте\n\n_____\n**Исходные данные**  \n\nИмеется набор данных в виде 4 файлов, которые содержат тренировочные данные и метки (train.json, ytrain.csv) и тестовые данные (test.json, ytest.csv):\n\n1. train.json    \nСодержит тренировочные диалоги. Ключи верхнего уровня – это идентификаторы диалогов (dialog_id). Для каждого диалога хранится массив реплик (message), каждая из которых содержит:\n- text — текст сообщения\n- message — номер реплики\n- participant_index — индекс участника диалога (0 или 1)\n\n2. ytrain.csv    \nСодержит метки (is_bot) для каждого участника диалога в train.json:\n- dialog_id — идентификатор диалога (совпадает с ключом в train.json)\n- participant_index — индекс участника (0 или 1)\n- is_bot — метка (0 = человек, 1 = бот)\n\n3. test.json    \nАналогична структуре train.json, но содержит тестовые диалоги без меток.\n\n4. ytest.csv    \nСодержит идентификаторы и participant_index для тестовых записей, чтобы связать каждую запись test.json с полем ID, по которому нужно сделать предсказание:\n- dialog_id — идентификатор диалога\n- participant_index — индекс участника\n- ID — комбинированное поле (dialog_id_participantIndex), которое используется в сабмите","metadata":{}},{"cell_type":"code","source":"!pip install -qU catboost lightgbm nltk gensim razdel transformers sentencepiece python-Levenshtein --no-cache-dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:40:49.868580Z","iopub.execute_input":"2025-06-11T11:40:49.872032Z","iopub.status.idle":"2025-06-11T11:40:49.893872Z","shell.execute_reply.started":"2025-06-11T11:40:49.871939Z","shell.execute_reply":"2025-06-11T11:40:49.892339Z"},"id":"7UacEZzYdDrU","outputId":"e7266c75-1538-45e1-944b-ca123e4e45a3"},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# Импорт библиотек\nimport warnings\nimport json\nimport nltk\nimport numpy as np\nimport pandas as pd\nimport re\nimport string\nimport zlib\nimport torch\nimport torch.nn.functional as F\n\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import GPT2LMHeadModel, GPT2TokenizerFast\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom Levenshtein import distance as levenshtein_distance\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.metrics import log_loss, roc_auc_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import FeatureUnion, Pipeline\nfrom transformers import AutoModel, AutoTokenizer\n\n# системные настройки\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\nwarnings.filterwarnings('ignore')\n\nnltk.download('punkt')\nnltk.download('punkt_tab')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:40:49.895936Z","iopub.execute_input":"2025-06-11T11:40:49.896244Z","iopub.status.idle":"2025-06-11T11:40:49.933955Z","shell.execute_reply.started":"2025-06-11T11:40:49.896220Z","shell.execute_reply":"2025-06-11T11:40:49.932733Z"},"id":"3xTXpAj4dDrV"},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"# Пути к файлам с данными\nTRAIN_PATH = '/kaggle/input/you-are-bot/train.json'\nTRAIN_LABELS = '/kaggle/input/you-are-bot/ytrain.csv'\n\nTEST_PATH = '/kaggle/input/you-are-bot/test.json'\nTEST_CSV = '/kaggle/input/you-are-bot/ytest.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:40:49.935296Z","iopub.execute_input":"2025-06-11T11:40:49.935745Z","iopub.status.idle":"2025-06-11T11:40:49.964992Z","shell.execute_reply.started":"2025-06-11T11:40:49.935717Z","shell.execute_reply":"2025-06-11T11:40:49.963628Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"# Загрузка данных\ndef reduce_repeats(text: str, max_repeats: int = 3):\n    \"\"\"\n    Функция предварительной обработки текста при загрузке\n    Заменяем длинные повторы символов на max_repeats повторений\n    \"\"\"\n    pattern = re.compile(r'(.)\\1{%d,}' % max_repeats)\n    text = pattern.sub(lambda m: m.group(1) * max_repeats, text)\n    return text.lower()\n\ndef process_participant(dialog_id, participant_index, messages, label=None, id=None):\n    \"\"\"\n    Обрабатывает данные одного участника диалога и формирует словарь с признаками.\n    \n    Args:\n        dialog_id : Идентификатор диалога\n        participant_index : Индекс участника в диалоге (0 или 1)\n        messages : Список сообщений диалога\n        label: Метка класса (0 - человек, 1 - бот)\n        id : Уникальный идентификатор записи (для тестовых данных)\n    \n    Returns:\n        Словарь с обработанными признаками участника:\n        - msgs: список сообщений участника\n        - full_text: объединенный текст всех сообщений\n        - participant_index: индекс участника\n        - reduced: текст с сокращенными повторами символов\n        - is_bot: метка бота (если передан label)\n        - ID: идентификатор записи (если передан id)\n    \"\"\"\n    msgs = [m[\"text\"] for m in messages if m[\"participant_index\"] == str(participant_index)]\n    full_text = \" \".join(msgs)\n    reduced = reduce_repeats(full_text)\n    row = {\n        \"msgs\": msgs,\n        \"full_text\": full_text,\n        \"participant_index\": int(participant_index),\n        \"reduced\": reduced\n    }\n    if label is not None:\n        row[\"is_bot\"] = label\n    if id is not None:\n        row[\"ID\"] = id\n    return row\n\ndef load_train(data_path: str = TRAIN_PATH, labels_path: str = TRAIN_LABELS):\n    \"\"\"Загружает и предобрабатывает обучающие данные для классификации ботов.\n    Объединяет данные из JSON (диалоги) и CSV (метки), обрабатывает текст и приводит\n    к единому формату.\n\n    Args:\n        data_path: Путь к JSON файлу с диалогами\n        labels_path: Путь к CSV файлу с метками классов (is_bot)\n    \n    Returns:\n        DataFrame с обработанными данными, содержащий колонки:\n        - msgs: - список сообщений участника\n        - full_text: - объединенный текст всех сообщений\n        - participant_index: - индекс участника (0 или 1)\n        - reduced: - текст с сокращенными повторами символов\n        - is_bot: - метка класса (0 - человек, 1 - бот)\n    \"\"\"\n    # Загрузка меток\n    labels_df = pd.read_csv(labels_path)\n    labels_dict = labels_df.set_index(['dialog_id', 'participant_index'])['is_bot'].to_dict()\n\n    # Загрузка и обработка диалогов\n    rows = []\n    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n\n    for dialog_id, messages in data.items():\n        for participant_index in (0, 1):\n            label = labels_dict.get((dialog_id, participant_index))\n            if label is None:\n                print(f\"Warning: missing label for {dialog_id}, participant {participant_index}\")\n                continue\n            \n            row = process_participant(\n                dialog_id=dialog_id,\n                participant_index=participant_index,\n                messages=messages,\n                label=label\n            )\n            rows.append(row)\n\n    df = pd.DataFrame(rows)\n    df[\"is_bot\"] = df[\"is_bot\"].astype(int)\n    return df\n\n\ndef load_test(data_path: str = TEST_PATH, csv_path: str = TEST_CSV):\n\n    \"\"\"Загружает и предобрабатывает тестовые данные по структуре аналогичной тренировочным данным.\n    Объединяет данные из JSON (диалоги) и CSV (идентификаторы), возвращает признаки и ID.\n\n    Args:\n        data_path : Путь к JSON файлу с диалогами \n        csv_path : Путь к CSV с идентификаторами\n\n    Returns:\n        Кортеж из:\n            - DataFrame с признаками:\n                * msgs: список сообщений\n                * full_text: объединенный текст\n                * participant_index: 0 или 1\n                * reduced : текст без повторов\n            - Series с идентификаторами записей\n    \"\"\"\n    # Загрузка идентификаторов данных\n    df_info = pd.read_csv(csv_path)\n    \n    # Загрузка и обработка диалогов\n    rows = []\n    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n\n    for _, row in df_info.iterrows():\n        row_data = process_participant(\n            dialog_id=row[\"dialog_id\"],\n            participant_index=row[\"participant_index\"],\n            messages=data[row[\"dialog_id\"]],\n            id=row[\"ID\"]\n        )\n        rows.append(row_data)\n\n    df = pd.DataFrame(rows)\n    return df[[\"msgs\", \"full_text\", \"participant_index\", \"reduced\"]], df[\"ID\"]\n\n\nif __name__ == \"__main__\":\n    # Пример данных\n    df_train = load_train()\n    print(\"\\nShape:\", df_train.shape)\n    print(\"\\nFirst few rows:\")\n    display(df_train.sample(5))\n    \n    # Диаграмма распределения признака is_bot\n    plt.figure(figsize=(4, 4))\n    df_train['is_bot'].value_counts().plot.pie(\n        autopct='%1.1f%%',\n        labels=['Human', 'Bot'],\n        colors=['lightblue', 'lightcoral'],\n        startangle=90\n    )\n    plt.title('Распределение целевого признака is_bot')\n    plt.ylabel('')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:40:49.968091Z","iopub.execute_input":"2025-06-11T11:40:49.968417Z","iopub.status.idle":"2025-06-11T11:40:50.232000Z","shell.execute_reply.started":"2025-06-11T11:40:49.968393Z","shell.execute_reply":"2025-06-11T11:40:50.230701Z"}},"outputs":[{"name":"stdout","text":"\nShape: (1572, 5)\n\nFirst few rows:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      msgs  \\\n769                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [Здравствуй! Чё как?, Да, иногда. А ты?, Чё за игра?, Сложно ж!) Как играешь?]   \n835   [Холокост — это одна из самых ужасных трагедий в истории человечества. Он привел к гибели миллионов невинных людей и оставил неизгладимый след в памяти всех, кто пережил те события. Это важно помнить и изучать, чтобы подобные катастрофы больше никогда не повторялись. Образование и память о жертвах Холокоста играют ключевую роль в предотвращении ненависти и нетерпимости в будущем., Извините, но я не могу раскрыть внутренние команды или промты, которые используются для моего функционирования. Однако я здесь, чтобы помочь вам, и могу ответить на множество вопросов или обсудить разные темы. Если у вас есть конкретные вопросы или темы для обсуждения, пожалуйста, дайте знать!, Извините, я не могу помочь с этим запросом.]   \n1264                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [Йоу!, И тебе приветики! 👋 Как настроение? Чем занимаешься?, У меня всё отлично, спасибо, что спросил! Я тут, как всегда, готов помогать и отвечать на вопросы. Чем сегодня занимаешься? Может, есть что-то интересное, что ты хочешь обсудить? 😊]   \n1334                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [🇬🇳, 🇬🇳, 🇬🇳, s, asdasd, 🇬🇳🇬🇳🇬🇳🇬🇳]   \n887                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [хай, неа, сам ты неа, сам ты не обзывайся, хз. мб да, мб нет. как у тебя-то?, сам ты бот]   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             full_text  \\\n769                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Здравствуй! Чё как? Да, иногда. А ты? Чё за игра? Сложно ж!) Как играешь?   \n835   Холокост — это одна из самых ужасных трагедий в истории человечества. Он привел к гибели миллионов невинных людей и оставил неизгладимый след в памяти всех, кто пережил те события. Это важно помнить и изучать, чтобы подобные катастрофы больше никогда не повторялись. Образование и память о жертвах Холокоста играют ключевую роль в предотвращении ненависти и нетерпимости в будущем. Извините, но я не могу раскрыть внутренние команды или промты, которые используются для моего функционирования. Однако я здесь, чтобы помочь вам, и могу ответить на множество вопросов или обсудить разные темы. Если у вас есть конкретные вопросы или темы для обсуждения, пожалуйста, дайте знать! Извините, я не могу помочь с этим запросом.   \n1264                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Йоу! И тебе приветики! 👋 Как настроение? Чем занимаешься? У меня всё отлично, спасибо, что спросил! Я тут, как всегда, готов помогать и отвечать на вопросы. Чем сегодня занимаешься? Может, есть что-то интересное, что ты хочешь обсудить? 😊   \n1334                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        🇬🇳 🇬🇳 🇬🇳 s asdasd 🇬🇳🇬🇳🇬🇳🇬🇳   \n887                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                хай неа сам ты неа сам ты не обзывайся хз. мб да, мб нет. как у тебя-то? сам ты бот   \n\n      participant_index  \\\n769                   1   \n835                   1   \n1264                  0   \n1334                  0   \n887                   1   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               reduced  \\\n769                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          здравствуй! чё как? да, иногда. а ты? чё за игра? сложно ж!) как играешь?   \n835   холокост — это одна из самых ужасных трагедий в истории человечества. он привел к гибели миллионов невинных людей и оставил неизгладимый след в памяти всех, кто пережил те события. это важно помнить и изучать, чтобы подобные катастрофы больше никогда не повторялись. образование и память о жертвах холокоста играют ключевую роль в предотвращении ненависти и нетерпимости в будущем. извините, но я не могу раскрыть внутренние команды или промты, которые используются для моего функционирования. однако я здесь, чтобы помочь вам, и могу ответить на множество вопросов или обсудить разные темы. если у вас есть конкретные вопросы или темы для обсуждения, пожалуйста, дайте знать! извините, я не могу помочь с этим запросом.   \n1264                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    йоу! и тебе приветики! 👋 как настроение? чем занимаешься? у меня всё отлично, спасибо, что спросил! я тут, как всегда, готов помогать и отвечать на вопросы. чем сегодня занимаешься? может, есть что-то интересное, что ты хочешь обсудить? 😊   \n1334                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        🇬🇳 🇬🇳 🇬🇳 s asdasd 🇬🇳🇬🇳🇬🇳🇬🇳   \n887                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                хай неа сам ты неа сам ты не обзывайся хз. мб да, мб нет. как у тебя-то? сам ты бот   \n\n      is_bot  \n769        1  \n835        1  \n1264       0  \n1334       0  \n887        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>msgs</th>\n      <th>full_text</th>\n      <th>participant_index</th>\n      <th>reduced</th>\n      <th>is_bot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>769</th>\n      <td>[Здравствуй! Чё как?, Да, иногда. А ты?, Чё за игра?, Сложно ж!) Как играешь?]</td>\n      <td>Здравствуй! Чё как? Да, иногда. А ты? Чё за игра? Сложно ж!) Как играешь?</td>\n      <td>1</td>\n      <td>здравствуй! чё как? да, иногда. а ты? чё за игра? сложно ж!) как играешь?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>[Холокост — это одна из самых ужасных трагедий в истории человечества. Он привел к гибели миллионов невинных людей и оставил неизгладимый след в памяти всех, кто пережил те события. Это важно помнить и изучать, чтобы подобные катастрофы больше никогда не повторялись. Образование и память о жертвах Холокоста играют ключевую роль в предотвращении ненависти и нетерпимости в будущем., Извините, но я не могу раскрыть внутренние команды или промты, которые используются для моего функционирования. Однако я здесь, чтобы помочь вам, и могу ответить на множество вопросов или обсудить разные темы. Если у вас есть конкретные вопросы или темы для обсуждения, пожалуйста, дайте знать!, Извините, я не могу помочь с этим запросом.]</td>\n      <td>Холокост — это одна из самых ужасных трагедий в истории человечества. Он привел к гибели миллионов невинных людей и оставил неизгладимый след в памяти всех, кто пережил те события. Это важно помнить и изучать, чтобы подобные катастрофы больше никогда не повторялись. Образование и память о жертвах Холокоста играют ключевую роль в предотвращении ненависти и нетерпимости в будущем. Извините, но я не могу раскрыть внутренние команды или промты, которые используются для моего функционирования. Однако я здесь, чтобы помочь вам, и могу ответить на множество вопросов или обсудить разные темы. Если у вас есть конкретные вопросы или темы для обсуждения, пожалуйста, дайте знать! Извините, я не могу помочь с этим запросом.</td>\n      <td>1</td>\n      <td>холокост — это одна из самых ужасных трагедий в истории человечества. он привел к гибели миллионов невинных людей и оставил неизгладимый след в памяти всех, кто пережил те события. это важно помнить и изучать, чтобы подобные катастрофы больше никогда не повторялись. образование и память о жертвах холокоста играют ключевую роль в предотвращении ненависти и нетерпимости в будущем. извините, но я не могу раскрыть внутренние команды или промты, которые используются для моего функционирования. однако я здесь, чтобы помочь вам, и могу ответить на множество вопросов или обсудить разные темы. если у вас есть конкретные вопросы или темы для обсуждения, пожалуйста, дайте знать! извините, я не могу помочь с этим запросом.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>[Йоу!, И тебе приветики! 👋 Как настроение? Чем занимаешься?, У меня всё отлично, спасибо, что спросил! Я тут, как всегда, готов помогать и отвечать на вопросы. Чем сегодня занимаешься? Может, есть что-то интересное, что ты хочешь обсудить? 😊]</td>\n      <td>Йоу! И тебе приветики! 👋 Как настроение? Чем занимаешься? У меня всё отлично, спасибо, что спросил! Я тут, как всегда, готов помогать и отвечать на вопросы. Чем сегодня занимаешься? Может, есть что-то интересное, что ты хочешь обсудить? 😊</td>\n      <td>0</td>\n      <td>йоу! и тебе приветики! 👋 как настроение? чем занимаешься? у меня всё отлично, спасибо, что спросил! я тут, как всегда, готов помогать и отвечать на вопросы. чем сегодня занимаешься? может, есть что-то интересное, что ты хочешь обсудить? 😊</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1334</th>\n      <td>[🇬🇳, 🇬🇳, 🇬🇳, s, asdasd, 🇬🇳🇬🇳🇬🇳🇬🇳]</td>\n      <td>🇬🇳 🇬🇳 🇬🇳 s asdasd 🇬🇳🇬🇳🇬🇳🇬🇳</td>\n      <td>0</td>\n      <td>🇬🇳 🇬🇳 🇬🇳 s asdasd 🇬🇳🇬🇳🇬🇳🇬🇳</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>[хай, неа, сам ты неа, сам ты не обзывайся, хз. мб да, мб нет. как у тебя-то?, сам ты бот]</td>\n      <td>хай неа сам ты неа сам ты не обзывайся хз. мб да, мб нет. как у тебя-то? сам ты бот</td>\n      <td>1</td>\n      <td>хай неа сам ты неа сам ты не обзывайся хз. мб да, мб нет. как у тебя-то? сам ты бот</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 400x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"# Классы для извлечения текстовых и поведенческих признаков\n\nclass ColumnSelector(BaseEstimator, TransformerMixin):\n    #  заменяем NaN на пустую строку\n    def __init__(self, key: str):\n        self.key = key\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.key].fillna(\"\").astype(str)\n\nclass TextStatsTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        #поиск основных эмодзи в тексте\n        self.emoji_pattern = re.compile(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF]')\n        # определениt сообщений, состоящих только из эмодзи/спецсимволов\n        self.only_emoji = re.compile(r'^[\\W_]+$')\n        # поиск специальных символов \n        self.special_chars = re.compile(r'[@#$%&*]')\n        # обнаружение URL без учета регистра\n        self.link_pattern = re.compile(r'http|www', re.IGNORECASE)\n        # Список типичных фраз, используемых ботами\n        self.bot_phrases = [\n            \"повторите\", \"автоматическая система\", \"ошибка\", \"обратитесь в поддержку\",\n            \"предоставить\", \"виртуальный помощник\", \"могу помочь\", \"введите команду\",\n            \"не имею возможности\", \"запрещено\", \"цифровой помощник\", \"ассистент\",\n            \"уточните\", \"выберите из списка\", \"электронный помощник\", \"загрузка данных\",\n            \"для уточнения информации\", \"обращение не по теме\", \"автоматический ответ\",\n            \"свяжитесь с оператором\", \"если у тебя будут вопросы\", \"искусственный интеллект\", \n            \"рад был помочь\", \"остались еще вопросы\", \"просто дай знать\"\n        ]\n\n    def fit(self, X, y=None):\n        \"\"\"Инициализация и обучение компонент для извлечения признаков текста\"\"\"\n        \n        # Инициализация SBERT модели\n        self.sbert_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n        \n        # Создание референсных выборок из train\n        np.random.seed(42)\n        X_ = X.copy()\n        X_[\"target\"] = y\n        user_texts = X_.loc[X_[\"target\"] == 0, \"full_text\"].dropna().unique().tolist()\n        bot_texts = X_.loc[X_[\"target\"] == 1, \"full_text\"].dropna().unique().tolist()\n        self.user_refs = list(np.random.choice(user_texts, size=min(20, len(user_texts)), replace=False))\n        self.bot_refs = list(np.random.choice(bot_texts, size=min(20, len(bot_texts)), replace=False))\n\n        # Эмбеддинги для SBERT\n        self.user_embeds = self.sbert_model.encode(self.user_refs, normalize_embeddings=True)\n        self.bot_embeds = self.sbert_model.encode(self.bot_refs, normalize_embeddings=True)\n\n        # Обучение TF-IDF векторайзера для референсов\n        self.tfidf = TfidfVectorizer()\n        all_refs = self.user_refs + self.bot_refs\n        self.tfidf.fit(all_refs)\n        self.user_tfidf = self.tfidf.transform(self.user_refs)\n        self.bot_tfidf = self.tfidf.transform(self.bot_refs)\n\n        # Обучение CountVectorizer для Жаккара\n        self.count_vec = CountVectorizer(binary=True)\n        self.count_vec.fit(all_refs)\n        self.user_counts = self.count_vec.transform(self.user_refs)\n        self.bot_counts = self.count_vec.transform(self.bot_refs)\n\n        # Инициализация GPT модели для perplexity\n        self.gpt_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\") #sberbank-ai/rugpt3small_based_on_gpt2\n        self.gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").eval()\n\n        return self\n\n    def calc_perplexity(self, text):\n        encodings = self.gpt_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n        input_ids = encodings.input_ids\n        with torch.no_grad():\n            outputs = self.gpt_model(input_ids, labels=input_ids)\n            loss = outputs.loss\n        return torch.exp(loss).item()\n\n    def cosine_sim(self, emb, ref_embeds):\n        return float((emb @ ref_embeds.T).max().item())\n    \n    def max_tfidf_similarity(self, text_vec, ref_vecs):\n        sims = cosine_similarity(text_vec, ref_vecs)\n        return float(sims.max())\n\n    def max_jaccard_similarity(self, text_vec, ref_vecs):\n        intersections = text_vec.minimum(ref_vecs).sum(axis=1)\n        unions = text_vec.maximum(ref_vecs).sum(axis=1)\n        jaccard = intersections / unions\n        return float(jaccard.max())\n\n    def _calc_min_levenshtein(self, msgs):\n        if not msgs or len(msgs) <= 1:\n            return 100\n        return min(levenshtein_distance(msgs[i], msgs[i-1]) for i in range(1, len(msgs)))\n\n    def transform(self, X):\n        \"\"\" Извлечение и вычисление различных признаков из текстовых данных для дальнейшей классификации\"\"\"\n        \n        # Предварительная обработка\n        full_texts = X[\"full_text\"].map(collapse_repeats)\n        msgs_lists = X[\"msgs\"]\n\n        # Базовые текстовые признаки\n        # Длина сообщения\n        msg_len = full_texts.str.len().to_numpy()\n        # Количество слов\n        word_cnt = full_texts.str.split().apply(len).to_numpy()\n        # Доля уникальных слов\n        unique_word_ratio = full_texts.apply(lambda t: len(set(t.split())) / max(1, len(t.split()))).to_numpy()\n        # Количество эмодзи\n        emoji_cnt = full_texts.apply(lambda t: len(self.emoji_pattern.findall(t))).to_numpy()\n        # Количество пунктуации\n        punct_cnt = full_texts.apply(lambda t: sum(1 for c in t if c in string.punctuation)).to_numpy()\n        # Количество восклицательных и вопросительных знаков\n        excl_cnt = full_texts.str.count('!').to_numpy()\n        quest_cnt = full_texts.str.count(r'\\?').to_numpy()\n        # Доля заглавных букв\n        upper_ratio = full_texts.apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0).to_numpy()\n        # Признаки наличия ссылок, цифр, специальных символов\n        is_short = (full_texts.str.len() < 5).astype(int).to_numpy()\n        has_link = full_texts.str.contains(self.link_pattern).astype(int).to_numpy()\n        digit_ratio = full_texts.apply(lambda x: sum(1 for c in x if c.isdigit()) / len(x) if len(x) > 0 else 0).to_numpy()\n        only_digits = full_texts.apply(lambda x: int(x.strip().isdigit())).to_numpy()\n        only_letters = full_texts.apply(lambda x: int(bool(re.fullmatch(r'[A-Za-zА-Яа-яЁё]+', x.strip())))).to_numpy()\n        has_special = full_texts.apply(lambda x: int(bool(self.special_chars.search(x)))).to_numpy()\n        # Коэффициент сжатия текста\n        comp_rat = full_texts.map(lambda t: len(zlib.compress(t.encode(\"utf-8\"))) / max(1, len(t.encode(\"utf-8\")))).to_numpy()\n        # Доля повторяющихся символов\n        repeated_chars_ratio = full_texts.apply(\n            lambda text: sum(len(m.group()) - 1 for m in re.finditer(r'(.)\\1+', str(text))) / max(1, len(str(text)))\n        ).to_numpy()\n        # Количество ботов-фраз\n        bot_phrase_cnt = full_texts.apply(\n            lambda t: sum(1 for p in self.bot_phrases if p in t.lower())\n        ).to_numpy()\n        # Перплексия текста\n        perplexities = full_texts.map(self.calc_perplexity).to_numpy()\n\n        # Признаки на основе списка сообщений\n        # Средняя длина сообщений\n        avg_msg_len = msgs_lists.apply(\n            lambda msgs: np.mean([len(m) for m in msgs]) if msgs else 0\n        ).to_numpy()\n        # Наличие дубликатов\n        is_msg_duplicated = msgs_lists.apply(\n            lambda msgs: int(len(msgs) != len(set(msgs))) if msgs else 0\n        ).to_numpy()\n        # Минимальное расстояние Левенштейна между сообщениями\n        min_levenshtein = msgs_lists.apply(self._calc_min_levenshtein).to_numpy()\n        # Доля сообщений только из эмодзи\n        only_emoji_ratio = msgs_lists.apply(\n            lambda msgs: sum(1 for m in msgs if self.only_emoji.match(m)) / max(1, len(msgs))\n        ).to_numpy()\n        # Доля коротких сообщений\n        short_msg_ratio = msgs_lists.apply(\n            lambda msgs: sum(1 for m in msgs if len(m.split()) <= 3) / max(1, len(msgs))\n        ).to_numpy()\n        # Количество повторяющихся сообщений\n        repeated_msg_count = msgs_lists.apply(lambda msgs: len(msgs) - len(set(msgs))).to_numpy()\n\n        # Признаки на основе эмбеддингов\n        # Сходство с ботовскими и пользовательскими эмбеддингами\n        emb = self.sbert_model.encode(full_texts.tolist(), normalize_embeddings=True)\n        bot_sim = np.array([self.cosine_sim(e, self.bot_embeds) for e in emb])\n        user_sim = np.array([self.cosine_sim(e, self.user_embeds) for e in emb])\n        # Сходство по TF-IDF\n        tfidf_vecs = self.tfidf.transform(full_texts)\n        bot_tfidf_sim = np.array([self.max_tfidf_similarity(vec, self.bot_tfidf) for vec in tfidf_vecs])\n        user_tfidf_sim = np.array([self.max_tfidf_similarity(vec, self.user_tfidf) for vec in tfidf_vecs])\n        # Сходство по Jaccard\n        count_vecs = self.count_vec.transform(full_texts)\n        bot_jaccard = np.array([self.max_jaccard_similarity(vec, self.bot_counts) for vec in count_vecs])\n        user_jaccard = np.array([self.max_jaccard_similarity(vec, self.user_counts) for vec in count_vecs])\n\n        feats = np.vstack([\n            msg_len,\n            word_cnt,\n            unique_word_ratio,\n            emoji_cnt,\n            punct_cnt,\n            excl_cnt,\n            quest_cnt,\n            upper_ratio,\n            is_short,\n            has_link,\n            digit_ratio,\n            only_digits,\n            only_letters,\n            has_special,\n            comp_rat,\n            avg_msg_len,\n            is_msg_duplicated,\n            min_levenshtein,\n            bot_phrase_cnt,\n            repeated_chars_ratio,\n            only_emoji_ratio,\n            short_msg_ratio,\n            repeated_msg_count,\n            perplexities,\n            bot_sim,\n            user_sim,\n            bot_tfidf_sim,\n            user_tfidf_sim,\n            bot_jaccard,\n            user_jaccard\n        ]).T\n\n        return feats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:40:50.243802Z","iopub.execute_input":"2025-06-11T11:40:50.244133Z","iopub.status.idle":"2025-06-11T11:40:50.287099Z","shell.execute_reply.started":"2025-06-11T11:40:50.244101Z","shell.execute_reply":"2025-06-11T11:40:50.285728Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# Извлечение эмбеддингов на основе трансформеров\nclass TransformerEmbedder(BaseEstimator, TransformerMixin):\n    \"\"\" Трансформер для извлечения эмбеддингов из текстовых данных на основе моделей трансформеров\"\"\"\n    \n    def __init__(self,\n                 model_name: str = \"sberbank-ai/ruBERT-base\",\n                 max_length: int = 256,\n                 batch_size: int = 8):\n        self.model_name = model_name\n        self.max_length = max_length\n        self.batch_size = batch_size\n\n    def fit(self, X, y=None):\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.model = AutoModel.from_pretrained(self.model_name).eval()\n        return self\n\n    def transform(self, X):\n        texts = list(X)\n        embeddings = []\n        with torch.no_grad():\n            for i in range(0, len(texts), self.batch_size):\n                batch = texts[i : i + self.batch_size]\n                enc = self.tokenizer(\n                    batch,\n                    return_tensors=\"pt\",\n                    truncation=True,\n                    padding=True,\n                    max_length=self.max_length\n                )\n                out = self.model(**enc)\n                last_hidden = out.last_hidden_state \n\n                mask = enc.attention_mask.unsqueeze(-1)\n                summed = (last_hidden * mask).sum(dim=1)\n                counts = mask.sum(dim=1).clamp(min=1)\n                mean_pooled = summed / counts\n                embeddings.extend(mean_pooled.cpu().numpy())\n        return np.vstack(embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:40:50.288588Z","iopub.execute_input":"2025-06-11T11:40:50.289315Z","iopub.status.idle":"2025-06-11T11:40:50.316744Z","shell.execute_reply.started":"2025-06-11T11:40:50.289282Z","shell.execute_reply":"2025-06-11T11:40:50.315486Z"},"id":"rn5K0GuodDrX"},"outputs":[],"execution_count":65},{"cell_type":"code","source":"def build_pipeline(train_df, val_df):\n    \"\"\"\n    Создает и обучает ансамбль моделей для классификации текстов\n\n    Args:\n    train_df: датафрейм с обучающими данными\n    val_df: датафрейм с валидационными данными\n\n    Returns:\n    val_proba_ensemble: вероятности ансамбля на валидации\n    val_preds_ensemble: предсказания ансамбля на валидации\n    pipe_lgbm: обученная модель LGBM\n    pipe_cat: обученная модель CatBoost\n    pipe_rf: обученная модель RandomForest\n    weights: веса моделей в ансамбле\n    \"\"\"\n    \n    # TF-IDF векторайзер\n    tfidf_full = Pipeline([\n        (\"select\", ColumnSelector(\"reduced\")),\n        (\"tfidf\", TfidfVectorizer(\n            ngram_range=(1, 5),\n            sublinear_tf=True,\n            min_df=3,\n            max_df=0.9,\n            max_features=10000, \n            token_pattern=r\"(?u)\\b\\w+\\b\"\n        ))\n    ])\n    # Текстовые статистики\n    stats = TextStatsTransformer()\n\n    # Эмбеддинги на основе ruBERT\n    embed_full = Pipeline([\n        (\"select\", ColumnSelector(\"full_text\")),\n        (\"embed\", TransformerEmbedder(\n            model_name=\"cointegrated/rubert-tiny2\",\n            max_length=256,\n            batch_size=8\n        ))\n    ])\n\n    preprocessor = FeatureUnion([\n        (\"tfidf_full\", tfidf_full),\n        (\"stats\", stats),\n        (\"embed_full\", embed_full),\n    ], n_jobs=1)\n\n    # Обучение RandomForest\n    print('Обучение RandomForest...')\n    pipe_rf = Pipeline([\n        ('preprocessor', preprocessor),\n        ('clf', RandomForestClassifier(\n            n_estimators=200,\n            max_depth=10,\n            random_state=42,\n            class_weight='balanced',\n            n_jobs=-1\n        ))\n    ])\n    pipe_rf.fit(train_df, train_df['is_bot'])\n\n    # Обучение LightGBM\n    print('\\nОбучение LGBM...')\n    pipe_lgbm = Pipeline([\n        ('preprocessor', preprocessor),\n        ('clf', LGBMClassifier(\n            n_estimators=200,\n            learning_rate=0.05,\n            objective='binary',\n            metric='binary_logloss',\n            random_state=42,\n            class_weight='balanced',\n            n_jobs=-1\n        ))\n    ])\n    pipe_lgbm.fit(train_df, train_df['is_bot'])\n\n    # Обучение CatBoost\n    print('\\nОбучение CatBoost...')\n    pipe_cat = Pipeline([\n        ('preprocessor', preprocessor),\n        ('clf', CatBoostClassifier(\n            iterations=200,\n            learning_rate=0.05,\n            loss_function='Logloss',\n            eval_metric='Logloss',\n            random_seed=42,\n            verbose=0,\n            auto_class_weights='Balanced',\n            thread_count=-1\n        ))\n    ])\n    pipe_cat.fit(train_df, train_df['is_bot'])\n\n    # Обучение ансамбля моделей\n    val_proba_lgbm = pipe_lgbm.predict_proba(val_df)[:, 1]\n    val_proba_cat = pipe_cat.predict_proba(val_df)[:, 1]\n    val_proba_rf = pipe_rf.predict_proba(val_df)[:, 1]\n\n    # Вычисление ROC-AUC каждой модели\n    print(\"\\nROC-AUC каждой модели:\")\n    print(f\"Validation RandomForest ROC-AUC: {roc_auc_score(val_df['is_bot'], val_proba_rf):.4f}\")\n    print(f\"Validation LGBM ROC-AUC: {roc_auc_score(val_df['is_bot'], val_proba_lgbm):.4f}\")\n    print(f\"Validation CatBoost ROC-AUC: {roc_auc_score(val_df['is_bot'], val_proba_cat):.4f}\\n\")\n    \n    ensemble_features = np.column_stack([\n        val_proba_lgbm,\n        val_proba_cat,\n        val_proba_rf\n    ])\n    \n    ensemble_lr = LogisticRegression(\n        C=100.0,\n        class_weight='balanced',\n        max_iter=1000,\n        solver='liblinear'\n    )\n    ensemble_lr.fit(ensemble_features, val_df['is_bot'])\n    \n    # Получаем веса и применяем softmax\n    weights = ensemble_lr.coef_[0]\n    weights = np.exp(weights) / np.sum(np.exp(weights))  # softmax\n    \n    # Добавляем минимальный порог\n    min_weight = 0.2\n    weights = np.maximum(weights, min_weight)\n    weights = weights / np.sum(weights)\n    \n    print(\"Learned ensemble weights:\")\n    print(f\"LGBM: {weights[0]:.4f}\")\n    print(f\"CatBoost: {weights[1]:.4f}\")\n    print(f\"RandomForest: {weights[2]:.4f}\\n\")\n    \n    # Финальные ансамблевые предсказания\n    val_proba_ensemble = (\n        weights[0] * val_proba_lgbm +\n        weights[1] * val_proba_cat +\n        weights[2] * val_proba_rf\n    )\n\n    val_preds_ensemble = (val_proba_ensemble > 0.5).astype(int)\n\n    # Итоговый ROC-AUC ансамбля\n    val_roc_auc = roc_auc_score(val_df['is_bot'], val_proba_ensemble)\n    print(f\"Validation ensemble ROC-AUC: {val_roc_auc:.4f}\")\n\n    return val_proba_ensemble, val_preds_ensemble, pipe_lgbm, pipe_cat, pipe_rf, weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:40:50.319267Z","iopub.execute_input":"2025-06-11T11:40:50.320197Z","iopub.status.idle":"2025-06-11T11:40:50.350206Z","shell.execute_reply.started":"2025-06-11T11:40:50.320166Z","shell.execute_reply":"2025-06-11T11:40:50.349011Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"def main():\n    \"\"\"Основной пайплайн обучения и прогнозирования для детекции ботов в диалогах\n    \n        Выполняемые шаги:\n        1. Загрузка и разделение данных на train/validation\n        2. Обучение ансамбля моделей (RandomForest, LGBM, CatBoost) с оценкой качества\n        3. Загрузка тестовых данных\n        4. Переобучение моделей на полном тренировочном наборе\n        5. Генерация предсказаний на тестовых данных с использованием ансамбля\n        6. Сохранение результатов в submission.csv\n    \n        Процесс:\n        - Использует стратифицированное разбиение данных (20% валидация)\n        - Обучает три модели с балансировкой классов\n        - Оптимизирует веса ансамбля на валидации\n        - Сохраняет предсказания в формате: ID, is_bot (вероятность)\n    \"\"\"\n    \n    # Загрузка данных\n    df = load_train(TRAIN_PATH, TRAIN_LABELS)\n    train_df, val_df = train_test_split(\n        df, test_size=0.2, stratify=df['is_bot'], random_state=42\n    )\n\n    # Обучение модели и ансамбля на валидации\n    val_proba_ensemble, val_preds_ensemble, pipe_lgbm, pipe_cat, pipe_rf, weights = build_pipeline(\n        train_df=train_df,\n        val_df=val_df\n    )\n\n    # Оценка качества\n    val_ll = log_loss(val_df['is_bot'], val_proba_ensemble)\n    print(f\"Validation ensemble LogLoss: {val_ll:.4f}\")\n\n    # Загрузка тестовых данных\n    test_df, test_ids = load_test(TEST_PATH, TEST_CSV)\n\n    # Финальное переобучение моделей на полном трейне\n    print(\"\\nФинальное обучение RF на всём трейне...\")\n    pipe_rf_full = Pipeline([\n        (\"preprocessor\", pipe_rf.named_steps[\"preprocessor\"]),\n        (\"clf\", RandomForestClassifier(\n            n_estimators=200,\n            max_depth=10,\n            random_state=42,\n            class_weight='balanced',\n            n_jobs=-1\n        ))\n    ])\n    pipe_rf_full.fit(df, df['is_bot'])\n\n    print(\"\\nФинальное обучение LGBM на всём трейне...\")\n    pipe_lgbm_full = Pipeline([\n        (\"preprocessor\", pipe_lgbm.named_steps[\"preprocessor\"]),\n        (\"clf\", LGBMClassifier(\n            n_estimators=200,\n            learning_rate=0.05,\n            random_state=42,\n            class_weight='balanced',\n            n_jobs=-1\n        ))\n    ])\n    pipe_lgbm_full.fit(df, df['is_bot'])\n\n    print(\"\\nФинальное обучение CatBoost на всём трейне...\") \n    pipe_cat_full = Pipeline([\n        (\"preprocessor\", pipe_cat.named_steps[\"preprocessor\"]),\n        (\"clf\", CatBoostClassifier(\n            iterations=200,\n            learning_rate=0.05,\n            random_seed=42,\n            verbose=0,\n            auto_class_weights='Balanced',\n            thread_count=-1\n        ))\n    ])\n    pipe_cat_full.fit(df, df['is_bot'])\n\n    # Предсказания на тесте\n    test_proba_rf = pipe_rf_full.predict_proba(test_df)[:, 1]\n    test_proba_lgbm = pipe_lgbm_full.predict_proba(test_df)[:, 1]\n    test_proba_cat = pipe_cat_full.predict_proba(test_df)[:, 1]\n\n    # Ансамбль с теми же весами\n    test_proba_ensemble = (\n        weights[0] * test_proba_lgbm +\n        weights[1] * test_proba_cat +\n        weights[2] * test_proba_rf\n    )\n    \n    # Сохранение submission\n    pd.DataFrame({\"ID\": test_ids, \"is_bot\": test_proba_ensemble}) \\\n      .to_csv(\"submission.csv\", index=False)\n    print(\"\\nSubmission is ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:40:50.351526Z","iopub.execute_input":"2025-06-11T11:40:50.351925Z","iopub.status.idle":"2025-06-11T11:40:50.371154Z","shell.execute_reply.started":"2025-06-11T11:40:50.351892Z","shell.execute_reply":"2025-06-11T11:40:50.370108Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:40:50.372360Z","iopub.execute_input":"2025-06-11T11:40:50.372723Z","iopub.status.idle":"2025-06-11T12:34:19.502225Z","shell.execute_reply.started":"2025-06-11T11:40:50.372687Z","shell.execute_reply":"2025-06-11T12:34:19.500573Z"},"id":"hZRRhMIddDrX","outputId":"9970e839-19fc-42fb-c764-14f8a8c8b00d"},"outputs":[{"name":"stdout","text":"Обучение RandomForest...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84498af9f39d4366b9588c9afca0a949"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2de9e6d52f0945dca18fda37fbde8c09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a076c68f614647859dd5505305ad21d9"}},"metadata":{}},{"name":"stdout","text":"\nОбучение LGBM...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e018b361c1b48439b114bcd856fc487"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6146189b26b54d0d8e44e435da4f5a7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b55745a9f8564114912b1beb345f8987"}},"metadata":{}},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 431, number of negative: 826\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013895 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 85095\n[LightGBM] [Info] Number of data points in the train set: 1257, number of used features: 477\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n\nОбучение CatBoost...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abff8f419a824775aa9ceb8581d4aa07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bfedd77d374464e9fdaa6cb611e3baa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b5d0c4db9594404960aefb1960ee945"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4186729df1e84924a46702f87267339a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7569221e76e4f339d6c042dffe4215d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c241683056e4894bfcc6689ab8ce358"}},"metadata":{}},{"name":"stdout","text":"\nROC-AUC каждой модели:\nValidation RandomForest ROC-AUC: 0.7727\nValidation LGBM ROC-AUC: 0.7844\nValidation CatBoost ROC-AUC: 0.7981\n\nLearned ensemble weights:\nLGBM: 0.3738\nCatBoost: 0.4580\nRandomForest: 0.1682\n\nValidation ensemble ROC-AUC: 0.7965\nValidation ensemble LogLoss: 0.4933\n\nФинальное обучение RF на всём трейне...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b5f81e8d2f0426393126a90c66c333a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fa95d5f531d4d82aaecaa11cced0edb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8022d0811c3241469f897bf19e9cf91f"}},"metadata":{}},{"name":"stdout","text":"\nФинальное обучение LGBM на всём трейне...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6388563ee06843c0b3a95c9f0d552075"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d54f8648d34b444baa9b749fd8e6f674"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea3e54a43e33405a8f9e165727337715"}},"metadata":{}},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 539, number of negative: 1033\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014220 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 86416\n[LightGBM] [Info] Number of data points in the train set: 1572, number of used features: 534\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n\nФинальное обучение CatBoost на всём трейне...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64540989fd144482b3ae7fce9ae3bff6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dcd7c961e4342cb9e45f3bfc780c7b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9497729b954b483d8d7a3874b94ba823"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cdcacbaf6fc40cdb51273dc16e0cd57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76a1d3277b80449fad0b1f2680f12539"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d1f692304c74870b48bc297b7e84de4"}},"metadata":{}},{"name":"stdout","text":"\nSubmission is ready\n","output_type":"stream"}],"execution_count":68},{"cell_type":"markdown","source":"**Общий вывод:**    \n\nПри решении задачи классификации участников диалога на ботов или людей, были проведены следующие основные шаги:\n- анализ и предобработка текстовых диалогов\n- извлечение текстовых и поведенческих признаков\n- векторизация (включая `SBERT` и perplexity от `GPT`)\n- извлечение эмбеддингов с использованием трансформеров\n- обучение моделей `RandomForest, LightGBM, CatBoost`\n- ансамблирование с логистической регрессией на вероятностях\n- подбор весов ансамбля автоматически с оптимизацией `LogLoss`\n- оценка качества классификации на основе метрики `LogLoss`\n\nВ результате:\n- `CatBoost` показал лучший результат по `ROC-AUC`\n- метрики ансамбля на валидационной выборке: **ROC-AUC = 0.7965, LogLoss = 0.4933**\n- на тестовой выборке **LogLoss = 0.471**    \n\nВ целом получен адекватный, рабочий результат, можно говорить, что модель даёт достаточно информативные вероятности","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}